{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import abspath\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import requests\n",
    "import json\n",
    "from livyc import livyc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_location = abspath('spark-warehouse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_livy = {\n",
    "    \"livy_server_url\": \"localhost\",\n",
    "    \"port\": \"8998\",\n",
    "    \"jars\": [\"org.sqlserver:mssql-jdbc-12.2.0.jre11.jar\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"host\": \"localhost\", \"port\":\"1433\", \"database\": \"db\", \"table\":\"BIGDATA\", \"user\": \"sa\", \"password\": \"123\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/28 23:53:33 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.22.24.52:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8a45d73070>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.master\",\"local[*]\")\n",
    "conf.set(\"spark.executor.memory\", \"4g\")\n",
    "conf.set(\"spark.driver.memory\", \"4g\")\n",
    "conf.set(\"spark.sql.adaptive.enabled\",\"true\")\n",
    "conf.set('spark.driver.extraClassPath', r\"/home/guilherme/pysparkapp/mssql-jdbc-12.2.0.jre11.jar\")\n",
    "conf.set('spark.executor.extraClassPath', r\"/home/guilherme/pysparkapp/mssql-jdbc-12.2.0.jre11.jar\")\n",
    "spark = SparkSession.builder\\\n",
    "            .config(conf=conf)\\\n",
    "            .config(\"spark.sql.warehouse.dir\", warehouse_location)\\\n",
    "            .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "            .enableHiveSupport() \\\n",
    "            .getOrCreate()\n",
    "    \n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'starting', 'id': 0, 'kind': 'spark'}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, pprint, requests, textwrap\n",
    "\n",
    "{u'state': u'starting', u'id': 0, u'kind': u'spark'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unrecognized field \"code\" (class org.apache.livy.server.interactive.CreateInteractiveRequest), not marked as ignorable (15 known properties: \"executorCores\", \"conf\", \"driverMemory\", \"name\", \"driverCores\", \"pyFiles\", \"archives\", \"kind\", \"files\", \"jars\", \"proxyUser\", \"numExecutors\", \"heartbeatTimeoutInSecond\", \"queue\", \"executorMemory\"])\\n at [Source: (org.eclipse.jetty.server.HttpInputOverHTTP); line: 1, column: 11] (through reference chain: org.apache.livy.server.interactive.CreateInteractiveRequest[\"code\"])'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host = 'http://localhost:8998'\n",
    "data = {'code': 'sc.parallelize(1 to 10).count()'}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "r = requests.post(host + '/sessions', data=json.dumps(data), headers=headers)\n",
    "r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"from\":0,\"total\":0,\"sessions\":[]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8998/sessions\"\n",
    "\n",
    "payload = {}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'starting', 'id': 0, 'kind': 'spark'}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "host = 'http://localhost:8998'\n",
    "data = {'kind': 'spark'}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "r = requests.post(host + '/sessions', data=json.dumps(data), headers=headers)\n",
    "\n",
    "r.json()\n",
    "{u'state': u'starting', u'id': 0, u'kind': u'spark'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "url = \"http://localhost:8998\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"file\": \"hdfs://10.250.36.25:9000/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibs/o2ov2.coding.category-1.0.0-GET.jar\",\n",
    "  \"className\": \"com.nielseniq.o2ov2.catecoding.O2OV2CategoryCodingSplitApp\",\n",
    "  \"jars\": [\n",
    "    \"hdfs://localhost:8998/projects/O2OV2/APP_PACKAGE/DEV/O2OV2CommonLibs/*\",\n",
    "    \"hdfs://localhost:8998/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibs/CommonInfra-2.10.0-O2OV2.jar\",\n",
    "    \"hdfs://localhost:8998/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibs/o2ov2.common-1.0.0.jar\"\n",
    "  ],\n",
    "  \"name\": \"DEV_O2OV2_CategoryCoding_GET_20221404\",\n",
    "  \"driverMemory\": \"4g\",\n",
    "  \"executorMemory\": \"4g\",\n",
    "  \"numExecutors\": 7,\n",
    "  \"executorCores\": 4\n",
    "})\n",
    "headers = {\n",
    "  'X-Requested-By': 'admin',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"http://localhost:8998/batches/1\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"file\": \"hdfs://10.250.36.25:9000/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibsTemp/o2ov2.coding.keywords-1.0.0.jar\",\n",
    "  \"className\": \"com.nielseniq.o2ov2.keywords.VUBApp\",\n",
    "  \"jars\": [\n",
    "    \"hdfs://localhost:8998/projects/O2OV2/APP_PACKAGE/DEV/O2OV2CommonLibs/*\",\n",
    "    \"hdfs://1localhost:8998/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibsTemp/o2ov2.common-1.0.0.jar\",\n",
    "    \"hdfs://localhost:8998/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibsTemp/CommonInfra-2.10.0-O2OV2.jar\",\n",
    "    \"hdfs://localhost:8998/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibsTemp/DataValidator-2.10.0-O2OV2.jar\",\n",
    "    \"hdfs://localhost:8998/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibsTemp/KeywordsCoding-2.10.0-O2OV2.jar\"\n",
    "  ],\n",
    "  \"name\": \"DEV_O2OV2_VUBCoding_20221410\",\n",
    "  \"driverMemory\": \"4g\",\n",
    "  \"executorMemory\": \"4g\",\n",
    "  \"numExecutors\": 7,\n",
    "  \"executorCores\": 4\n",
    "})\n",
    "headers = {\n",
    "  'X-Requested-By': 'admin',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "r = requests.post(host + '/sessions', data=json.dumps(data), headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'state': 'idle'}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'kind': 'pyspark'}\n",
    "r = requests.post(host + '/sessions', data=json.dumps(data), headers=headers)\n",
    "r.json()\n",
    "\n",
    "{u'id': 1, u'state': u'idle'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': None, 'state': 'running', 'id': 0}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statements_url = url + '/statements'\n",
    "data = {'code': '1 + 1'}\n",
    "r = requests.post(host + '/sessions', data=json.dumps(data), headers=headers)\n",
    "r.json()\n",
    "\n",
    "{u'output': None, u'state': u'running', u'id': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Unrecognized field \"code\" (class '\n",
      " 'org.apache.livy.server.interactive.CreateInteractiveRequest), not marked as '\n",
      " 'ignorable (15 known properties: \"executorCores\", \"conf\", \"driverMemory\", '\n",
      " '\"name\", \"driverCores\", \"pyFiles\", \"archives\", \"kind\", \"files\", \"jars\", '\n",
      " '\"proxyUser\", \"numExecutors\", \"heartbeatTimeoutInSecond\", \"queue\", '\n",
      " '\"executorMemory\"])\\n'\n",
      " ' at [Source: (org.eclipse.jetty.server.HttpInputOverHTTP); line: 1, column: '\n",
      " '11] (through reference chain: '\n",
      " 'org.apache.livy.server.interactive.CreateInteractiveRequest[\"code\"])')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 12,\n",
       " 'output': {'data': {'text/plain': 'Pi is roughly 3.136000'},\n",
       "  'execution_count': 12,\n",
       "  'status': 'ok'},\n",
       " 'state': 'running'}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "  'code': textwrap.dedent(\"\"\"\n",
    "    import random\n",
    "    NUM_SAMPLES = 100000\n",
    "    def sample(p):\n",
    "      x, y = random.random(), random.random()\n",
    "      return 1 if x*x + y*y < 1 else 0\n",
    "\n",
    "    count = sc.parallelize(xrange(0, NUM_SAMPLES)).map(sample).reduce(lambda a, b: a + b)\n",
    "    print \"Pi is roughly %f\" % (4.0 * count / NUM_SAMPLES)\n",
    "    \"\"\")\n",
    "}\n",
    "\n",
    "r = requests.post(host + '/sessions', data=json.dumps(data), headers=headers)\n",
    "pprint.pprint(r.json())\n",
    "\n",
    "{u'id': 12,\n",
    "u'output': {u'data': {u'text/plain': u'Pi is roughly 3.136000'},\n",
    "            u'execution_count': 12,\n",
    "            u'status': u'ok'},\n",
    "u'state': u'running'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cannot construct instance of '\n",
      " '`org.apache.livy.server.interactive.CreateInteractiveRequest` (although at '\n",
      " 'least one Creator exists): no String-argument constructor/factory method to '\n",
      " \"deserialize from String value ('\\n\"\n",
      " '\\n'\n",
      " '    from pyspark.sql.functions import udf, col, explode\\n'\n",
      " '    from pyspark.sql.types import StructType, StructField, IntegerType, '\n",
      " 'StringType, ArrayType\\n'\n",
      " '    from pyspark.sql import Row\\n'\n",
      " '    from pyspark.sql import SparkSession\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '    df = spark.read.format(\"jdbc\")         .option(\"url\", '\n",
      " '\"jdbc:postgresql://{host}:{port}/{database}\")         .option(\"driver\", '\n",
      " '\"org.postgresql.Driver\")         .option(\"dbtable\", \"{table}\")         '\n",
      " '.option(\"user\", \"{user}\")         .option(\"password\", \"{password}\")         '\n",
      " '.load()\\n'\n",
      " '        \\n'\n",
      " '    n_rows = df.count()\\n'\n",
      " '\\n'\n",
      " '    spark.stop()\\n'\n",
      " \"')\\n\"\n",
      " ' at [Source: (org.eclipse.jetty.server.HttpInputOverHTTP); line: 1, column: '\n",
      " '1]')\n"
     ]
    }
   ],
   "source": [
    "pyspark_script = \"\"\"\n",
    "\n",
    "    from pyspark.sql.functions import udf, col, explode\n",
    "    from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType\n",
    "    from pyspark.sql import Row\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "    df = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://{host}:{port}/{database}\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"dbtable\", \"{table}\") \\\n",
    "        .option(\"user\", \"{user}\") \\\n",
    "        .option(\"password\", \"{password}\") \\\n",
    "        .load()\n",
    "        \n",
    "    n_rows = df.count()\n",
    "\n",
    "    spark.stop()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "r = requests.post(host + '/sessions', data=json.dumps(pyspark_script), headers=headers)\n",
    "pprint.pprint(r.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'http://localhost:8998'\n",
    "data = {'kind': 'spark'}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "r = requests.post(host + '/sessions', data=json.dumps(data), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url = \"http://localhost:8999/batches\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"file\": \"hdfs://10.250.36.25:9000/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibsTemp/o2ov2.coding.cnn-1.0.0.jar\",\n",
    "  \"className\": \"com.nielseniq.o2ov2.cnncoding.O2OPredictionApp\",\n",
    "  \"jars\": [\n",
    "    \"hdfs://localhost:8999/projects/O2OV2/APP_PACKAGE/DEV/O2OV2CommonLibs/*\",\n",
    "    \"hdfs://localhost:8999/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibsTemp/o2ov2.common-1.0.0.jar\",\n",
    "    \"hdfs://localhost:8999/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibsTemp/CommonInfra-2.10.0-O2OV2.jar\",\n",
    "    \"hdfs://localhost:8999/projects/O2OV2/APP_PACKAGE/DEV/O2OV2BizLibsTemp/CNNCoding-2.10.0-O2OV2.jar\"\n",
    "  ],\n",
    "  \"name\": \"DEV_O2OV2_CNNCoding_20221410\",\n",
    "  \"driverMemory\": \"4g\",\n",
    "  \"executorMemory\": \"4g\",\n",
    "  \"numExecutors\": 7,\n",
    "  \"executorCores\": 4\n",
    "})\n",
    "headers = {\n",
    "  'X-Requested-By': 'admin',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ./bin/spark-submit \\\n",
    "  --class org.apache.spark.examples.SparkPi \\\n",
    "  --master local[8] \\\n",
    "  /home/guilherme/pysparkapp/teste.py \\\n",
    "  100\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
